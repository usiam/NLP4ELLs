{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Import Necessay Library**"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:31.934069Z","iopub.status.busy":"2022-12-11T02:28:31.933670Z","iopub.status.idle":"2022-12-11T02:28:31.940210Z","shell.execute_reply":"2022-12-11T02:28:31.939068Z","shell.execute_reply.started":"2022-12-11T02:28:31.934033Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","from transformers import BertTokenizer, BertModel,RobertaConfig, RobertaModel,DebertaTokenizer,DebertaModel,RobertaTokenizer\n","from torch.optim import lr_scheduler\n","from torch import nn\n","from torch.optim import Adam\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["# **Load the data**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:34.254552Z","iopub.status.busy":"2022-12-11T02:28:34.254025Z","iopub.status.idle":"2022-12-11T02:28:34.379912Z","shell.execute_reply":"2022-12-11T02:28:34.378888Z","shell.execute_reply.started":"2022-12-11T02:28:34.254516Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3978</th>\n","      <td>AAAAAA000027</td>\n","      <td>ololoac</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3979</th>\n","      <td>AAAAAA000028</td>\n","      <td>wacmespqit</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3980</th>\n","      <td>AAAAAA000029</td>\n","      <td>havmess</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3981</th>\n","      <td>AAAAAA000030</td>\n","      <td>ilvaem</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3982</th>\n","      <td>AAAAAA000031</td>\n","      <td>vlavme</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3983 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["           text_id                                          full_text  \\\n","0     0016926B079C  I think that students would benefit from learn...   \n","1     0022683E9EA5  When a problem is a change you have to let it ...   \n","2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n","3     003885A45F42  The best time in life is when you become yours...   \n","4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n","...            ...                                                ...   \n","3978  AAAAAA000027                                            ololoac   \n","3979  AAAAAA000028                                         wacmespqit   \n","3980  AAAAAA000029                                            havmess   \n","3981  AAAAAA000030                                             ilvaem   \n","3982  AAAAAA000031                                             vlavme   \n","\n","      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n","0          3.5     3.5         3.0          3.0      4.0          3.0  \n","1          2.5     2.5         3.0          2.0      2.0          2.5  \n","2          3.0     3.5         3.0          3.0      3.0          2.5  \n","3          4.5     4.5         4.5          4.5      4.0          5.0  \n","4          2.5     3.0         3.0          3.0      2.5          2.5  \n","...        ...     ...         ...          ...      ...          ...  \n","3978       1.0     1.0         1.0          1.0      1.0          1.0  \n","3979       1.0     1.0         1.0          1.0      1.0          1.0  \n","3980       1.0     1.0         1.0          1.0      1.0          1.0  \n","3981       1.0     1.0         1.0          1.0      1.0          1.0  \n","3982       1.0     1.0         1.0          1.0      1.0          1.0  \n","\n","[3983 rows x 8 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('../../data/train.csv')\n","df.head()\n","data = [\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA000001\",\"xyz\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010000\",\"svem\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010001\",\"vmapb\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010002\",\"lserm\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA010003\",\"invew\",1,1,1,1,1,1],\n","[\"AAAAAA000002\",\"asc oism\",1,1,1,1,1,1],\n","[\"AAAAAA000003\",\"kkk texv\",1,1,1,1,1,1],\n","[\"AAAAAA000004\",\"tbp\",1,1,1,1,1,1],\n","[\"AAAAAA000005\",\"ltk asm\",1,1,1,1,1,1],\n","[\"AAAAAA000006\",\"kopvasd\",1,1,1,1,1,1],\n","[\"AAAAAA000007\",\"pasldg\",1,1,1,1,1,1],\n","[\"AAAAAA000008\",\"foclic\",1,1,1,1,1,1],\n","[\"AAAAAA000009\",\"imas podf\",1,1,1,1,1,1],\n","[\"AAAAAA000010\",\"mkcaiwepr\",1,1,1,1,1,1],\n","[\"AAAAAA000011\",\"lasmettes\",1,1,1,1,1,1],\n","[\"AAAAAA000012\",\"zmziawr\",1,1,1,1,1,1],\n","[\"AAAAAA000013\",\"masolef mvolse kkk\",1,1,1,1,1,1],\n","[\"AAAAAA000014\",\"maslemtdsgtymv\",1,1,1,1,1,1],\n","[\"AAAAAA000015\",\"olmsetw\",1,1,1,1,1,1],\n","[\"AAAAAA000016\",\"xyzliksmer\",1,1,1,1,1,1],\n","[\"AAAAAA000017\",\"zpo\",1,1,1,1,1,1],\n","[\"AAAAAA000018\",\"lcom\",1,1,1,1,1,1],\n","[\"AAAAAA000019\",\"blts\",1,1,1,1,1,1],\n","[\"AAAAAA000020\",\"cpla\",1,1,1,1,1,1],\n","[\"AAAAAA000021\",\"alzme\",1,1,1,1,1,1],\n","[\"AAAAAA000022\",\"dacple\",1,1,1,1,1,1],\n","[\"AAAAAA000023\",\"jaclem\",1,1,1,1,1,1],\n","[\"AAAAAA000024\",\"gacemwsl\",1,1,1,1,1,1],\n","[\"AAAAAA000025\",\"tpcmae\",1,1,1,1,1,1],\n","[\"AAAAAA000026\",\"elacem\",1,1,1,1,1,1],\n","[\"AAAAAA000027\",\"ololoac\",1,1,1,1,1,1],\n","[\"AAAAAA000028\",\"wacmespqit\",1,1,1,1,1,1],\n","[\"AAAAAA000029\",\"havmess\",1,1,1,1,1,1],\n","[\"AAAAAA000030\",\"ilvaem\",1,1,1,1,1,1],\n","[\"AAAAAA000031\",\"vlavme\",1,1,1,1,1,1]\n","]\n","append_df = pd.DataFrame(data = data, columns = df.columns)\n","df.append(append_df, ignore_index = True)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:35.571402Z","iopub.status.busy":"2022-12-11T02:28:35.570577Z","iopub.status.idle":"2022-12-11T02:28:35.639841Z","shell.execute_reply":"2022-12-11T02:28:35.638607Z","shell.execute_reply.started":"2022-12-11T02:28:35.571353Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train_Shape: (3911, 8),Test_Shape: (3, 2),Sample_Shape: (3, 7)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1552</th>\n","      <td>772D27D400BB</td>\n","      <td>It god to have a possitive attitude when you d...</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2114</th>\n","      <td>9E8F3C6405CA</td>\n","      <td>Why do people ask more then one person for adv...</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           text_id                                          full_text  \\\n","1552  772D27D400BB  It god to have a possitive attitude when you d...   \n","2114  9E8F3C6405CA  Why do people ask more then one person for adv...   \n","\n","      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n","1552       3.0     2.5         2.5          2.0      2.0          2.0  \n","2114       3.0     2.0         3.0          3.5      3.0          3.0  "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id                                          full_text\n","1  000BAD50D026  Do you think students would benefit from being...\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n","0  0000C359D63E       3.0     3.0         3.0          3.0      3.0   \n","2  00367BB2546B       3.0     3.0         3.0          3.0      3.0   \n","1  000BAD50D026       3.0     3.0         3.0          3.0      3.0   \n","\n","   conventions  \n","0          3.0  \n","2          3.0  \n","1          3.0  "]},"metadata":{},"output_type":"display_data"}],"source":["test = pd.read_csv('../../data/test.csv')\n","\n","print(f'Train_Shape: {df.shape},Test_Shape: {test.shape}')\n","display(df.sample(2))\n","display(test.sample(2))"]},{"cell_type":"markdown","metadata":{},"source":["# **Dataset_Class_Representation**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:42.320158Z","iopub.status.busy":"2022-12-11T02:28:42.319768Z","iopub.status.idle":"2022-12-11T02:28:42.369308Z","shell.execute_reply":"2022-12-11T02:28:42.368366Z","shell.execute_reply.started":"2022-12-11T02:28:42.320125Z"},"trusted":true},"outputs":[],"source":["#DatasetClass\n","\n","tokenizer = BertTokenizer.from_pretrained('../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased')\n","\n","class Dataset(torch.utils.data.Dataset):\n","    \n","    def __init__(self,df):\n","        \n","        self.labels = df[[\"cohesion\",\"syntax\",\"vocabulary\",\"phraseology\",\"grammar\",\"conventions\"]].reset_index()\n","        self.texts = df[[\"full_text\"]].reset_index()\n","    \n","    def classes(self):\n","        return self.labels\n","    \n","    def __len__(self):\n","        return len(self.labels)\n","    \n","    def get_batch_labels(self, idx):\n","        #fetch a batch of labels\n","        return np.array(self.labels.loc[idx].values[1:].astype(float))\n","        \n","        \n","    def get_batch_texts(self,idx):\n","        #fetch a batch of inputs\n","        return tokenizer(self.texts.loc[idx].values[1],\n","                        padding= 'max_length',max_length=512,truncation=True,\n","                        return_tensors='pt')\n","    \n","    def __getitem__(self,idx):\n","        \n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","        \n","        return batch_texts, batch_y"]},{"cell_type":"markdown","metadata":{},"source":["# **Build the Model - Pretrained_Bert-Base-Uncased**"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:42.834604Z","iopub.status.busy":"2022-12-11T02:28:42.833744Z","iopub.status.idle":"2022-12-11T02:28:42.843036Z","shell.execute_reply":"2022-12-11T02:28:42.841900Z","shell.execute_reply.started":"2022-12-11T02:28:42.834559Z"},"trusted":true},"outputs":[],"source":["#Create Model\n","class FeedbackELLModel(nn.Module):\n","    \n","    def __init__(self, dropout=0.1):\n","        \n","        super(FeedbackELLModel, self).__init__()\n","        self.bert = BertModel.from_pretrained('../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased')\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear = nn.Linear(768,256)\n","        self.relu = nn.ReLU()\n","        self.out = nn.Linear(256,6)\n","        \n","        \n","    def forward(self,input_id,mask):\n","        _, x = self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n","        x = self.dropout(x)\n","        x = self.linear(x)\n","        x = self.relu(x)\n","        final_layer = self.out(x)\n","        return final_layer\n","        \n","        "]},{"cell_type":"markdown","metadata":{},"source":["# **Train the Model**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:43.326827Z","iopub.status.busy":"2022-12-11T02:28:43.325825Z","iopub.status.idle":"2022-12-11T02:28:43.339225Z","shell.execute_reply":"2022-12-11T02:28:43.338199Z","shell.execute_reply.started":"2022-12-11T02:28:43.326789Z"},"trusted":true},"outputs":[],"source":["#Training function\n","def train(model, train_data, val_data, epochs):\n","\n","    train, val = Dataset(train_data), Dataset(val_data)\n","    if torch.cuda.is_available():  \n","        dev = \"cuda:0\" \n","    else:  \n","        dev = \"cpu\"  \n","    device = torch.device(dev) \n","    criterion = nn.MSELoss()\n","    optimizer = Adam(model.parameters(), lr=1e-5)\n","    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=500, \n","                                                                 eta_min=1e-6)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_loss_train = 0\n","\n","            for train_input, train_labels in tqdm(train_dataloader):\n","\n","                train_labels = train_labels.to(device).float()\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","                output = model(input_id, mask)\n","                \n","                batch_loss = criterion(output, train_labels)\n","                total_loss_train += batch_loss.item()\n","                \n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","                scheduler.step()\n","            \n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask)\n","\n","                    batch_loss = criterion(output, val_label)\n","                    total_loss_val += batch_loss.item()\n","                                \n","            print(f'Epoch: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f}')"]},{"cell_type":"markdown","metadata":{},"source":["# **Evaluate the Model**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:43.854412Z","iopub.status.busy":"2022-12-11T02:28:43.854041Z","iopub.status.idle":"2022-12-11T02:28:43.862016Z","shell.execute_reply":"2022-12-11T02:28:43.860848Z","shell.execute_reply.started":"2022-12-11T02:28:43.854381Z"},"trusted":true},"outputs":[],"source":["#valid\n","\n","def evaluate(model, test_data):\n","    \n","    test =  Dataset(test_data)\n","    \n","    test_dataloader = torch.utils.data.DataLoader(test,batch_size=2)\n","    criterion = nn.MSELoss()\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    \n","    if use_cuda:\n","        \n","        model = model.cuda()\n","        \n","    total_loss_test = 0\n","    with torch.no_grad():\n","        for test_input, test_labels in tqdm(test_dataloader):\n","            test_labels =  test_labels.to(device)\n","            mask = test_input[\"attention_mask\"].to(device)\n","            input_id = test_input[\"input_ids\"].squeeze(1).to(device)\n","            \n","            output =  model(input_id, mask)\n","            \n","            loss =  criterion(output,test_labels)\n","            total_loss_test += loss\n","            \n","    print(f'Test_Loss: {total_loss_test / len(test_data): .3f}')\n","            \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# **Split the data**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:44.378574Z","iopub.status.busy":"2022-12-11T02:28:44.377745Z","iopub.status.idle":"2022-12-11T02:28:44.388770Z","shell.execute_reply":"2022-12-11T02:28:44.387650Z","shell.execute_reply.started":"2022-12-11T02:28:44.378528Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train_Shape: 3519,Val_Shape: 196,Test_Shape: 196\n"]}],"source":["# split the data\n","np.random.seed(42)\n","\n","df_train, df_val, df_test = np.split(df.sample(frac=1,random_state=42),\n","                                    [int(.9*len(df)),\n","                                    int(.95*len(df))])\n","\n","print(f'Train_Shape: {len(df_train)},Val_Shape: {len(df_val)},Test_Shape: {len(df_test)}')"]},{"cell_type":"markdown","metadata":{},"source":["# **Intiate to train_Function and 5,10 Epochs!**"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T02:28:44.910449Z","iopub.status.busy":"2022-12-11T02:28:44.909732Z","iopub.status.idle":"2022-12-11T03:13:39.368971Z","shell.execute_reply":"2022-12-11T03:13:39.367880Z","shell.execute_reply.started":"2022-12-11T02:28:44.910412Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6df57fb92234fdbb3104865ca814c8a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Train Loss:  0.378 | Val Loss:  0.140\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d17d483b20ed4b0d9e60251d9d4aae1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | Train Loss:  0.123 | Val Loss:  0.128\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57ab998112a04b3ebbe443f1754d88f6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 3 | Train Loss:  0.107 | Val Loss:  0.121\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2eae2acb25074f71ad447349f2b1ae86","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 4 | Train Loss:  0.089 | Val Loss:  0.127\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9664af5d9d0436c9b0cf289a4564db9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 5 | Train Loss:  0.074 | Val Loss:  0.123\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a83cc7bdaf74fdab3433f7f75c44a9a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 6 | Train Loss:  0.064 | Val Loss:  0.134\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"153077f6554b4b46aa875101d355d267","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 7 | Train Loss:  0.059 | Val Loss:  0.121\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d56750545f6a4f24b36ebdefeff540a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 8 | Train Loss:  0.055 | Val Loss:  0.113\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1b1005c24034240b06a4b7b80946380","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 9 | Train Loss:  0.049 | Val Loss:  0.125\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d801c42eee1a4e4d93646be9c75e3bda","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1760 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 10 | Train Loss:  0.044 | Val Loss:  0.126\n"]}],"source":["#Run training\n","EPOCHS = 10\n","model = FeedbackELLModel()\n","\n","train(model, df_train, df_val, EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["# **Initiate to evaluate_function in validation data**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T03:13:39.372185Z","iopub.status.busy":"2022-12-11T03:13:39.371864Z","iopub.status.idle":"2022-12-11T03:13:43.360809Z","shell.execute_reply":"2022-12-11T03:13:43.359792Z","shell.execute_reply.started":"2022-12-11T03:13:39.372149Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5782276c861e436b91fe0e6cc26b8411","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test_Loss:  0.129\n"]}],"source":["#evaluate\n","evaluate(model, df_test)"]},{"cell_type":"markdown","metadata":{},"source":["# **Save the Model**"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-12-11T03:26:07.646596Z","iopub.status.busy":"2022-12-11T03:26:07.645873Z","iopub.status.idle":"2022-12-11T03:26:08.245719Z","shell.execute_reply":"2022-12-11T03:26:08.244591Z","shell.execute_reply.started":"2022-12-11T03:26:07.646557Z"},"trusted":true},"outputs":[],"source":["torch.save(model.cpu().state_dict(), \"BERT_BASE_UNCASED_UPDATE.bin\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
